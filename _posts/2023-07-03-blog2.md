---
layout: custom
title: "Having Fun with VAE"
date: 2023-07-03
categories: machine learning
---

# Having Fun with VAE

Recently, I had a lot of fun learning about Variational Autoencoders (VAE) and training a network for MNIST numbers generation. Visualizing the neuron activation map for each digit, as well as creating a manifold representation for two selected neurons, was especially inspiring. You can check out the corresponding notebook with model weights here: [GitHub Repository](https://github.com/egorpol/nnstuff/tree/main/mnist_vae).

Here are some pictures of these representations:

<a href="/assets/images/manifold.png" target="_blank">
  <img src="/assets/images/manifold.png" alt="Manifold Representation" style="width: 75%; display: block; margin: 0 auto;">
</a>

<a href="/assets/images/prototype.png" target="_blank">
  <img src="/assets/images/prototype.png" alt="Prototype Activation" style="width: 75%; display: block; margin: 0 auto;">
</a>