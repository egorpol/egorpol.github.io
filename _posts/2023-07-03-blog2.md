---
layout: post
title: "Constructing a VAE-based MNIST number generation Jupyter notebook with emphasis on visualizing latent space"
date: 2024-07-23
categories: machine learning
excerpt: "Learn how to construct a VAE-based MNIST number generation Jupyter notebook with an emphasis on visualizing latent space."
---


# Introduction to Variational Autoencoders (VAE) for MNIST Digit Generation

In this blog post, I will guide you through the process of coding a Variational Autoencoder (VAE) for MNIST digit generation. Our goals are to:

1. Explore the latent space using different embeddings
2. Analyze neuron activation patterns for each digit

> **Disclaimer**: I don't have a degree in Computer Science, nor am I an expert coder. This implementation is purely for educational purposes, aimed at learning how to represent symbolic music as a binary matrix based on piano roll representations. While the MNIST dataset differs significantly from symbolic music encoding, it serves as a valuable training ground for understanding general machine learning concepts and various model architectures.
>
> I frequently cross-check my code with ChatGPT and other large language models (LLMs), so the code examples may appear quite generic. Despite this, the code is functional and might be useful to others, which is why I'm sharing it here.

You can find the corresponding notebooks with model weights for different VAE setups in this [GitHub Repository](https://github.com/egorpol/nnstuff/tree/main/mnist_vae).

The `requirements.txt` file can be found [here](https://github.com/egorpol/nnstuff/blob/main/mnist_vae/requirements.txt).


## General Information and Resources about VAEs

For a general understanding of VAEs, you can check out the following resources:

- [Original VAE paper](https://arxiv.org/pdf/1312.6114)
- Excellent blog posts I found on the web:
  - [VAE Tutorial by Ava Soleimany](https://avandekleut.github.io/vae/)
  - [VAE Tutorial with Keras Implementation](https://tiao.io/post/tutorial-on-variational-autoencoders-with-a-concise-keras-implementation/)
  - [VAE Explained by Lilian Weng](https://lilianweng.github.io/posts/2018-08-12-vae/)

## Setting up the Notebook and Dataset

We'll be programming our VAE setup in PyTorch. Let's start by setting up our device:

```python
import torch

# Check for GPU availability
if torch.cuda.is_available():
    print("Using GPU:", torch.cuda.get_device_name(0))
else:
    print("No GPU available, using the CPU instead.")

# Define device
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
```
This is a standard cell that I always use at the beginning to ensure the proper device is selected. By reusing the `device` variable, we can maintain consistent use of the right device throughout our code.
Next, we'll set up our dataset loader:

```python
from mnist_loader import load_mnist, plot_sample_images

# Load the MNIST dataset
train_loader, test_loader = load_mnist(num_samples_train=60000, num_samples_test=10000, batch_size=64)  

# Plot sample images
plot_sample_images(train_loader)
```    
Here, we're using the `mnist_loader.py` script to download and set up the MNIST dataset locally. You can find the full script [here](https://github.com/egorpol/nnstuff/blob/main/mnist_vae/mnist_loader.py).

I've extended the data loader with a set of functions aimed at providing additional information about the size of train and test data within the loaded dataset. It also includes a customized loader where we can define the exact number of images to use during training. This is particularly useful for experiments with very small training sets to see how many features can be extracted (I'll probably make a dedicated blog post about this in the future).

The loader includes data range printouts to ensure we're aware of the range of values being fed into the model. Some sample images are also plotted for reference.

### Key Features of the Custom MNIST Loader:

1. Flexible sample size: Allows specifying the number of samples for both training and test sets.
2. Batch size customization: Enables setting the batch size for data loading.
3. Data information: Provides details about the size of train and test datasets.
4. Value range verification: Prints the range of pixel values in the dataset.
5. Visual inspection: Includes a function to plot sample images from the dataset.

This custom loader enhances our ability to experiment with different dataset configurations and ensures we have a clear understanding of the data we're working with.

Here an example of the output: 

<a href="/assets/images/loader.png" target="_blank">
  <img src="/assets/images/loader.png" alt="Loader Output" style="width: 75%; display: block; margin: 0 auto;">
</a>

## Defining the Model

We are going for a conventional VAE model with convolutional and fully connected layers. The Python file with the model can be found [here](https://github.com/egorpol/nnstuff/blob/main/mnist_vae/enhanced_vae_model.py). Below is the corresponding Graphviz plot with `latent_dim = 10` (you can find the corresponding notebook [here](https://github.com/egorpol/nnstuff/blob/main/mnist_vae/visualize_model_graphviz.ipynb)):

<a href="/assets/images/vae_model_architecture.png" target="_blank">
  <img src="/assets/images/vae_model_architecture.png" alt="Model" style="width: 50%; display: block; margin: 0 auto;">
</a>

As the model follows the conventional VAE structure, I won't elaborate on topics such as convolutional/dense layers (an excellent summary can be found [here](https://medium.com/analytics-vidhya/dense-or-convolutional-part-1-c75c59c5b4ad)) or the reparameterization trick (you can find excellent sources on it like [this](https://sassafras13.github.io/ReparamTrick/) or [this](https://stats.stackexchange.com/questions/199605/how-does-the-reparameterization-trick-for-vaes-work-and-why-is-it-important)). Some decisions on the size of the model were made during initial testing, where I found the setup with 256 conv layers and 256=>512 dense layers very stable, especially with low `latent_dim` values (I couldn't make a system stable enough for values less than 3 though). 

The implementation of `kld_weight` into the loss function can help with training stability as well and act as a balancing factor between the reconstruction loss (BCE) and the regularization term (KLD). I will definitely explore this topic further in the future (especially the affect of different kld_weght on training process) but as a rule of thumb:

- `kld_weight > 1.0`:
  - Increases the importance of the KLD term
  - Encourages stronger regularization of the latent space
  - May lead to better disentanglement and more structured latent representations
  - Can potentially reduce reconstruction quality

- `kld_weight < 1.0`:
  - Decreases the importance of the KLD term
  - Prioritizes reconstruction quality over latent space regularization
  - May lead to better reconstructions but potentially less structured latent space
  - Can result in less disentangled representations

- `kld_weight = 0`:
  - Completely ignores the KLD term
  - VAE behaves more like a standard autoencoder
  - No regularization of the latent space
  - May lead to overfitting and poor generalization

- `kld_weight = 1.0` (default):
  - Balances both terms equally
  - Provides a good starting point for many VAE applications

An excellent blog about the effects of different `kld_weights` can be found [here](https://medium.com/@outerrencedl/variational-autoencoder-and-a-bit-kl-divergence-with-pytorch-ce04fd55d0d7).

```python
def loss_function(recon_x, x, mu, logvar, kld_weight=1.0):
    BCE = F.binary_cross_entropy(recon_x.view(-1, 784), x.view(-1, 784), reduction='sum')
    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
    return BCE + kld_weight * KLD
```
## Training

Although I am providing the weights for `latent_dim = 3, 4, 5, 9, 10, 15, 20, 32`, you can also train the VAE yourself with the train script ([available here](https://github.com/egorpol/nnstuff/blob/main/mnist_vae/vae_training.py)) and the following cell:


```python
from vae_training import VAETrainer, LossPlotter

# Assuming model, optimizer, train_loader, and device are already defined
trainer = VAETrainer(model, optimizer, train_loader, device, kld_weight=1.0)
train_losses = trainer.train(epochs=100, log_interval=50)

plotter = LossPlotter()
plotter.plot_losses(train_losses, scale='linear')  # Change 'linear' to 'log' for log scale
```
I found that training for 100 epochs yielded good results, but due to high loss fluctuations, especially with different `kld_weight` values, I added an option to show the learning curve plot also in log scale.

## Loading the Weights

To load the pretrained model weights, use the 'vae_model_gauss_enh10.pth' files and change the number within the file name according to the `latent_dim` setting:

```python
def load_model(model, path):
    # Check if CUDA is available
    if torch.cuda.is_available():
        # Load the model weights to GPU
        state_dict = torch.load(path)
    else:
        # Load the model weights to CPU
        state_dict = torch.load(path, map_location=torch.device('cpu'))
    
    # Load the state dict into the model
    model.load_state_dict(state_dict)
    
    # Set the model to evaluation mode
    model.eval()
    
    return model

# Example usage
model_path = 'vae_model_gauss_enh10.pth'
try:
    model = load_model(model, model_path)
    print("Model loaded successfully.")
except Exception as e:
    print(f"An error occurred while loading the model: {e}")
```
I've also integrated a dedicated call for CPU-based environments in case you want to run it without a GPU.

## Testing the Loaded/Trained Model

To inspect the functionality of the loaded model, we use some numbers with labels from the loaded test set and reconstruct them with the VAE. Although the MNIST numbers dataset isn't binary (the inputs for each pixel are set to the range of 0 to 1), I added binary output with a threshold of 0.5 for better visualization of reconstructed patterns within the numbers. I've also added a seed to replicate the exact same set of numbers every time the code is run. 

Generally:
- When you provide a seed, you'll get a consistent set of images across different runs or model comparisons.
- When you change the seed, you'll get a different set of images.
- If you don't provide a seed, you'll get a random set of images each time.

```python
import random
import matplotlib.pyplot as plt
import numpy as np

def binarize_image(image, threshold=0.5):
    return (image > threshold).astype(np.float32)

def visualize_results(model, data_loader, num_images=10, device='cuda', seed=None):
    if seed is not None:
        torch.manual_seed(seed)
        random.seed(seed)
        np.random.seed(seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed(seed)
            torch.cuda.manual_seed_all(seed)

    model.eval()
    
    # Get all data from the loader
    all_data = []
    all_labels = []
    with torch.no_grad():
        for data, labels in data_loader:
            all_data.append(data)
            all_labels.append(labels)
    
    all_data = torch.cat(all_data, dim=0)
    all_labels = torch.cat(all_labels, dim=0)
    
    # Always randomly select indices, but use the set seed if provided
    indices = random.sample(range(len(all_data)), num_images)
    
    # Get the selected data and labels
    selected_data = all_data[indices].to(device)
    selected_labels = all_labels[indices]
    
    # Get reconstructions
    with torch.no_grad():  # Ensure no gradients are computed
        recon, _, _ = model(selected_data)

    fig, axes = plt.subplots(4, num_images, figsize=(2 * num_images, 10))
    plt.subplots_adjust(wspace=0.1, hspace=0.5)

    row_labels = ['Original:', 'Binarized\nOriginal:', 'Reconstructed:', 'Binarized\nReconstructed:']
    
    for i in range(num_images):
        original = selected_data[i].cpu().numpy().reshape(28, 28)
        reconstructed = recon[i].cpu().detach().numpy().reshape(28, 28)
        
        images = [
            original,
            binarize_image(original),
            reconstructed,
            binarize_image(reconstructed)
        ]
        
        for j, img in enumerate(images):
            ax = axes[j, i]
            ax.imshow(img, cmap='viridis')
            ax.set_xticks([])
            ax.set_yticks([])
            
            if i == 0:
                ax.set_ylabel(row_labels[j], rotation=0, labelpad=70, fontsize=10, va='center')
            
            if j == 0:
                ax.set_title(f"Label: {selected_labels[i].item()}", fontsize=10, pad=5)

    plt.show()

# Example usage
num_images_to_display = 5
seed_value = 42  # Choose any integer value
visualize_results(model, test_loader, num_images=num_images_to_display, seed=seed_value)
```
As we can see in the rendered test images, the VAE's reconstructed output has the usual round/blurred edges (here's an old Stack Exchange thread about blurriness of VAE output: [Why is the Variational Auto-Encoder's output blurred while GAN's output is crisp?](https://ai.stackexchange.com/questions/8885/why-is-the-variational-auto-encoders-output-blurred-while-gans-output-is-crisp)). 

We can also clearly see differences within features of the reconstructed images. For example, look at how different the features are within the "9" (first column) in the top right corner, where the circle is connecting to the vertical line:

<a href="/assets/images/test_reconstructed.png" target="_blank">
  <img src="/assets/images/test_reconstructed.png" alt="Reconstructed Test Images" style="width: 75%; display: block; margin: 0 auto;">
</a>